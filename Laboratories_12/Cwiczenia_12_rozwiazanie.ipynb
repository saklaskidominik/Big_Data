{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "252bb077-9dfb-4c3c-9a52-d29940c0485b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Zadanie 1 \n",
    "\n",
    " \n",
    "Cel zadania – zapoznanie się z Spark UI zrób krótką notatkę z informacją co można znaleźć w poszczególnych elementach Spark UI Jobs > Stage >  Storage > Executors > SQL/Dataframe, gdzie jest informacja o dystrybucji danych?  \n",
    "\n",
    "Żeby uzyskać informacje o przebiegu zadań w Spark UI uruchom istniejący kod notatnik z poprzednich ćwiczeń np. data_generator.dbc z przykładami (agregacja, szufle, join ect) i przejdź przez Spark UI, powinieneś wiedzieć, gdzie znaleźć informację o tym co przetwarza Spark.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "658f83c0-d7a9-40a6-8758-805e0fe9c0e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Spark UI — zawartość poszczególnych sekcji\n",
    "1. Jobs\n",
    "W tej zakładce prezentowana jest lista wszystkich zadań (jobs) uruchomionych przez aplikację Spark. Dostępne są informacje o statusie zadań (czy zakończyły się sukcesem, czy są w trakcie lub zakończyły się błędem) oraz szczegóły dotyczące powiązanych etapów (Stages).\n",
    "\n",
    "2. Stages\n",
    "Sekcja Stages pokazuje podział zadań na etapy. Dla każdego etapu dostępne są szczegółowe informacje, takie jak liczba tasków, czas ich wykonania oraz operacje shuffle (liczba odczytów i zapisów). Pozwala to na analizę przebiegu przetwarzania oraz identyfikację ewentualnych wąskich gardeł.\n",
    "\n",
    "3. Storage\n",
    "Zakładka Storage zawiera informacje o zcache’owanych RDD lub DataFrame, ich rozmiarze oraz rozmieszczeniu w partycjach. Tutaj można sprawdzić dystrybucję danych w klastrze Spark oraz ilość zajmowanej pamięci.\n",
    "\n",
    "4. Executors\n",
    "W tej sekcji wyświetlane są szczegóły dotyczące poszczególnych executorów przetwarzających dane: poziom zużycia CPU, ilość dostępnej pamięci oraz liczba przetworzonych danych. Pozwala to ocenić, jak efektywnie wykorzystywane są zasoby klastra.\n",
    "\n",
    "5. SQL / DataFrame\n",
    "Zakładka SQL/DataFrame umożliwia przeglądanie uruchamianych zapytań SQL oraz DataFrame, a także planów ich wykonania (logical i physical plan), czasu trwania poszczególnych operacji oraz szczegółów dotyczących joinów, shuffle itp.\n",
    "\n",
    "\n",
    "Informacja o dystrybucji danych:\n",
    "Szczegóły na temat rozmieszczenia i wielkości partycji oraz rozkładu danych dostępne są przede wszystkim w zakładce Storage. Dodatkowe informacje dotyczące dystrybucji danych i sposobu ich przetwarzania znajdują się również w sekcji Stages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "606707ac-88d9-4634-b945-5c429d7fb762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Zadanie 2 \n",
    "\n",
    "Bucketing \n",
    "\n",
    "Wykorzystaj istniejące dane/notatniki. \n",
    "\n",
    "Przygotuj notatnik z przykładem użycia bucketing i porównaj go z partitionBy.  \n",
    "\n",
    "Dla tych samych danych wykonaj obie operacje i sprawdź czy będą różnice w plikach? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dc8d8e5-4a15-40df-bde2-a843cd42f096",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import rand\n",
    "\n",
    "dbutils.fs.rm(\"dbfs:/user/hive/warehouse/users_partitioned\", True)\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Bucketing Example\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.range(0, 10000).withColumn(\"user_id\", (rand() * 1000).cast(\"int\"))\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS users_bucketed\")\n",
    "df.write \\\n",
    "    .bucketBy(10, \"user_id\") \\\n",
    "    .sortBy(\"user_id\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"parquet\") \\\n",
    "    .saveAsTable(\"users_bucketed\")\n",
    "\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS users_partitioned\")\n",
    "df.write \\\n",
    "    .partitionBy(\"user_id\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"parquet\") \\\n",
    "    .saveAsTable(\"users_partitioned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e7ae709-0359-483f-92fa-40ae648f3539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Zadanie 3 \n",
    "\n",
    "Stwórz jedną tabelę i pobierz statystyki dla tabeli i wszystkich kolumn ANALYZE TABLE - Spark 3.5.1 Documentation (apache.org). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e46bfd04-941c-4ddd-a07c-36268b8ef9f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>format</th><th>id</th><th>name</th><th>description</th><th>location</th><th>createdAt</th><th>lastModified</th><th>partitionColumns</th><th>numFiles</th><th>sizeInBytes</th><th>properties</th><th>minReaderVersion</th><th>minWriterVersion</th><th>tableFeatures</th><th>statistics</th></tr></thead><tbody><tr><td>delta</td><td>b602c6de-6eeb-47ee-af8d-4da7dccbedbb</td><td>spark_catalog.default.my_sample_table</td><td>null</td><td>dbfs:/user/hive/warehouse/my_sample_table</td><td>2025-05-28T14:02:18.417+0000</td><td>2025-05-28T14:02:24.000+0000</td><td>List()</td><td>8</td><td>142550</td><td>Map()</td><td>1</td><td>2</td><td>List(appendOnly, invariants)</td><td>Map()</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "delta",
         "b602c6de-6eeb-47ee-af8d-4da7dccbedbb",
         "spark_catalog.default.my_sample_table",
         null,
         "dbfs:/user/hive/warehouse/my_sample_table",
         "2025-05-28T14:02:18.417+0000",
         "2025-05-28T14:02:24.000+0000",
         [],
         8,
         142550,
         {},
         1,
         2,
         [
          "appendOnly",
          "invariants"
         ],
         {}
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "format",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "createdAt",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "lastModified",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "partitionColumns",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "numFiles",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "sizeInBytes",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "properties",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "minReaderVersion",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "minWriterVersion",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "tableFeatures",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "statistics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"long\",\"valueContainsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Tworzenie przykładowej tabeli\n",
    "CREATE OR REPLACE TABLE my_sample_table AS\n",
    "SELECT\n",
    "    id,\n",
    "    rand() as random_value,\n",
    "    floor(rand() * 100) as group_id\n",
    "FROM range(10000);\n",
    "\n",
    "-- Obliczanie ogólnych statystyk (rekordy, pliki, itp.)\n",
    "ANALYZE TABLE my_sample_table COMPUTE STATISTICS;\n",
    "\n",
    "\n",
    "-- Obliczanie statystyk dla poszczególnych kolumn\n",
    "ANALYZE TABLE my_sample_table COMPUTE STATISTICS FOR COLUMNS id, random_value, group_id;\n",
    "\n",
    "\n",
    "-- Wyświetlenie szczegółowych informacji o tabeli\n",
    "DESCRIBE TABLE EXTENDED my_sample_table;\n",
    "\n",
    "\n",
    "-- Alternatywnie (np. w Databricks)\n",
    "DESCRIBE DETAIL my_sample_table;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75a95368-0639-4f7a-ae55-fa1f9f40a509",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "COMPUTE STATISTICS — pozwala zebrać ogólne informacje o tabeli, takie jak liczba rekordów, plików czy rozmiar danych.\n",
    "\n",
    "FOR COLUMNS — generuje szczegółowe statystyki dla wybranych kolumn, np. minimalna i maksymalna wartość, liczba różnych wartości czy liczba pustych rekordów.\n",
    "\n",
    "Te statystyki są wykorzystywane przez silnik Spark SQL do optymalizacji planów zapytań i efektywnego wykonywania operacji na danych."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 367042144011433,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Cwiczenia_12_rozwiazanie",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}