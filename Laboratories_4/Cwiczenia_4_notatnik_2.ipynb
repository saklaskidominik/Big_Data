{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abcae539-7cfd-4ed9-957f-f9343d80414a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e18c211-f981-466a-810a-38d73a7ed972",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, sum, avg, count, min, max, sum, lead, lag, first, last, row_number\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9cfef9e-3e74-425f-9efa-5ea605d932cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Zadanie 3\n",
    "\n",
    "Wykorzystaj przykłady z notatnika w SQL Windowed Aggregate Functions (cmd 11) i przepisz funkcje używając Spark API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2a625b6-31d7-43af-9470-af8525c99b72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactions_data = [\n",
    "    ( 1, '2011-01-01', 500),\n",
    "( 1, '2011-01-15', 50),\n",
    "( 1, '2011-01-22', 250),\n",
    "( 1, '2011-01-24', 75),\n",
    "( 1, '2011-01-26', 125),\n",
    "( 1, '2011-01-28', 175),\n",
    "( 2, '2011-01-01', 500),\n",
    "( 2, '2011-01-15', 50),\n",
    "( 2, '2011-01-22', 25),\n",
    "( 2, '2011-01-23', 125),\n",
    "( 2, '2011-01-26', 200),\n",
    "( 2, '2011-01-29', 250),\n",
    "( 3, '2011-01-01', 500),\n",
    "( 3, '2011-01-15', 50 ),\n",
    "( 3, '2011-01-22', 5000),\n",
    "( 3, '2011-01-25', 550),\n",
    "( 3, '2011-01-27', 95 ),\n",
    "( 3, '2011-01-30', 2500)\n",
    "]\n",
    "\n",
    "transactions_columns = [\"AccountId\", \"TranDate\", \"TranAmt\"]\n",
    "transactions_df = spark.createDataFrame(transactions_data, schema=transactions_columns)\n",
    "transactions_df.createOrReplaceTempView(\"Transactions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd2ee3e1-eceb-4bf8-9934-4c0f89de2a3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logical_data = [\n",
    "(1,'George', 800),\n",
    "(2,'Sam', 950),\n",
    "(3,'Diane', 1100),\n",
    "(4,'Nicholas', 1250),\n",
    "(5,'Samuel', 1250),\n",
    "(6,'Patricia', 1300),\n",
    "(7,'Brian', 1500),\n",
    "(8,'Thomas', 1600),\n",
    "(9,'Fran', 2450),\n",
    "(10,'Debbie', 2850),\n",
    "(11,'Mark', 2975),\n",
    "(12,'James', 3000),\n",
    "(13,'Cynthia', 3000),\n",
    "(14,'Christopher', 5000)\n",
    "]\n",
    "\n",
    "logical_columns = [\"RowID\", \"FName\", \"Salary\"]\n",
    "logical_df = spark.createDataFrame(logical_data, schema=logical_columns)\n",
    "logical_df.createOrReplaceTempView(\"Logical\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e615ca3-2dda-4bf6-bb13-3687c6b253ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* Totals based on previous row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e62e8922-260d-46d0-be4b-ed64519da1af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-----------+\n|AccountId|  TranDate|TranAmt|RunTotalAmt|\n+---------+----------+-------+-----------+\n|        1|2011-01-01|    500|        500|\n|        1|2011-01-15|     50|        550|\n|        1|2011-01-22|    250|        800|\n|        1|2011-01-24|     75|        875|\n|        1|2011-01-26|    125|       1000|\n|        1|2011-01-28|    175|       1175|\n|        2|2011-01-01|    500|        500|\n|        2|2011-01-15|     50|        550|\n|        2|2011-01-22|     25|        575|\n|        2|2011-01-23|    125|        700|\n|        2|2011-01-26|    200|        900|\n|        2|2011-01-29|    250|       1150|\n|        3|2011-01-01|    500|        500|\n|        3|2011-01-15|     50|        550|\n|        3|2011-01-22|   5000|       5550|\n|        3|2011-01-25|    550|       6100|\n|        3|2011-01-27|     95|       6195|\n|        3|2011-01-30|   2500|       8695|\n+---------+----------+-------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.partitionBy(\"AccountId\").orderBy(\"TranDate\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "transactions_df_with_running_total = transactions_df.withColumn(\"RunTotalAmt\", sum(\"TranAmt\").over(windowSpec))\n",
    "\n",
    "transactions_df_with_running_total.select(\"AccountId\", \"TranDate\", \"TranAmt\", \"RunTotalAmt\").orderBy(\"AccountId\", \"TranDate\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce5020d2-4d68-48ff-ad83-e03aeb9ffad0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-----------+\n|AccountId|  TranDate|TranAmt|RunTotalAmt|\n+---------+----------+-------+-----------+\n|        1|2011-01-01|  500.0|      500.0|\n|        1|2011-01-15|   50.0|      550.0|\n|        1|2011-01-22|  250.0|      800.0|\n|        1|2011-01-24|   75.0|      875.0|\n|        1|2011-01-26|  125.0|     1000.0|\n|        1|2011-01-28|  175.0|     1175.0|\n|        2|2011-01-01|  500.0|      500.0|\n|        2|2011-01-15|   50.0|      550.0|\n|        2|2011-01-22|   25.0|      575.0|\n|        2|2011-01-23|  125.0|      700.0|\n|        2|2011-01-26|  200.0|      900.0|\n|        2|2011-01-29|  250.0|     1150.0|\n|        3|2011-01-01|  500.0|      500.0|\n|        3|2011-01-15|   50.0|      550.0|\n|        3|2011-01-22| 5000.0|     5550.0|\n|        3|2011-01-25|  550.0|     6100.0|\n|        3|2011-01-27|   95.0|     6195.0|\n|        3|2011-01-30| 2500.0|     8695.0|\n+---------+----------+-------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum\n",
    "from pyspark.sql.window import Window\n",
    "import datetime\n",
    "\n",
    "# Załóżmy, że SparkSession została już zainicjalizowana i nazywa się `spark`\n",
    "\n",
    "# Przygotowanie danych\n",
    "transactions_data = [\n",
    "    (1, datetime.date(2011, 1, 1), 500.00),\n",
    "    (1, datetime.date(2011, 1, 15), 50.00),\n",
    "    (1, datetime.date(2011, 1, 22), 250.00),\n",
    "    (1, datetime.date(2011, 1, 24), 75.00),\n",
    "    (1, datetime.date(2011, 1, 26), 125.00),\n",
    "    (1, datetime.date(2011, 1, 28), 175.00),\n",
    "    (2, datetime.date(2011, 1, 1), 500.00),\n",
    "    (2, datetime.date(2011, 1, 15), 50.00),\n",
    "    (2, datetime.date(2011, 1, 22), 25.00),\n",
    "    (2, datetime.date(2011, 1, 23), 125.00),\n",
    "    (2, datetime.date(2011, 1, 26), 200.00),\n",
    "    (2, datetime.date(2011, 1, 29), 250.00),\n",
    "    (3, datetime.date(2011, 1, 1), 500.00),\n",
    "    (3, datetime.date(2011, 1, 15), 50.00),\n",
    "    (3, datetime.date(2011, 1, 22), 5000.00),\n",
    "    (3, datetime.date(2011, 1, 25), 550.00),\n",
    "    (3, datetime.date(2011, 1, 27), 95.00),\n",
    "    (3, datetime.date(2011, 1, 30), 2500.00)\n",
    "]\n",
    "\n",
    "# Tworzenie DataFrame\n",
    "transactions_columns = [\"AccountId\", \"TranDate\", \"TranAmt\"]\n",
    "transactions_df = spark.createDataFrame(transactions_data, schema=transactions_columns)\n",
    "\n",
    "# Specyfikacja okna dla sumy kumulatywnej\n",
    "windowSpec = Window.partitionBy(\"AccountId\").orderBy(\"TranDate\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "# Obliczanie bieżącej sumy\n",
    "transactions_df = transactions_df.withColumn(\"RunTotalAmt\", sum(\"TranAmt\").over(windowSpec))\n",
    "\n",
    "# Wyświetlanie wyników\n",
    "transactions_df.select(\"AccountId\", \"TranDate\", \"TranAmt\", \"RunTotalAmt\").orderBy(\"AccountId\", \"TranDate\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af29a303-2122-4248-a940-75db53deeb22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+------------------+----------+-----------+-----------+-----------+\n|AccountId|  TranDate|TranAmt|            RunAvg|RunTranQty|RunSmallAmt|RunLargeAmt|RunTotalAmt|\n+---------+----------+-------+------------------+----------+-----------+-----------+-----------+\n|        1|2011-01-01|  500.0|             500.0|         1|      500.0|      500.0|      500.0|\n|        1|2011-01-15|   50.0|             275.0|         2|       50.0|      500.0|      550.0|\n|        1|2011-01-22|  250.0| 266.6666666666667|         3|       50.0|      500.0|      800.0|\n|        1|2011-01-24|   75.0|            218.75|         4|       50.0|      500.0|      875.0|\n|        1|2011-01-26|  125.0|             200.0|         5|       50.0|      500.0|     1000.0|\n|        1|2011-01-28|  175.0|195.83333333333334|         6|       50.0|      500.0|     1175.0|\n|        2|2011-01-01|  500.0|             500.0|         1|      500.0|      500.0|      500.0|\n|        2|2011-01-15|   50.0|             275.0|         2|       50.0|      500.0|      550.0|\n|        2|2011-01-22|   25.0|191.66666666666666|         3|       25.0|      500.0|      575.0|\n|        2|2011-01-23|  125.0|             175.0|         4|       25.0|      500.0|      700.0|\n|        2|2011-01-26|  200.0|             180.0|         5|       25.0|      500.0|      900.0|\n|        2|2011-01-29|  250.0|191.66666666666666|         6|       25.0|      500.0|     1150.0|\n|        3|2011-01-01|  500.0|             500.0|         1|      500.0|      500.0|      500.0|\n|        3|2011-01-15|   50.0|             275.0|         2|       50.0|      500.0|      550.0|\n|        3|2011-01-22| 5000.0|            1850.0|         3|       50.0|     5000.0|     5550.0|\n|        3|2011-01-25|  550.0|            1525.0|         4|       50.0|     5000.0|     6100.0|\n|        3|2011-01-27|   95.0|            1239.0|         5|       50.0|     5000.0|     6195.0|\n|        3|2011-01-30| 2500.0|1449.1666666666667|         6|       50.0|     5000.0|     8695.0|\n+---------+----------+-------+------------------+----------+-----------+-----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.partitionBy(\"AccountId\").orderBy(\"TranDate\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "transactions_df = transactions_df.withColumn(\"RunAvg\", avg(\"TranAmt\").over(windowSpec)) \\\n",
    "                                 .withColumn(\"RunTranQty\", count(\"*\").over(windowSpec)) \\\n",
    "                                 .withColumn(\"RunSmallAmt\", min(\"TranAmt\").over(windowSpec)) \\\n",
    "                                 .withColumn(\"RunLargeAmt\", max(\"TranAmt\").over(windowSpec)) \\\n",
    "                                 .withColumn(\"RunTotalAmt\", sum(\"TranAmt\").over(windowSpec))\n",
    "\n",
    "transactions_df.select(\"AccountId\", \"TranDate\", \"TranAmt\", \"RunAvg\", \"RunTranQty\", \"RunSmallAmt\", \"RunLargeAmt\", \"RunTotalAmt\") \\\n",
    "               .orderBy(\"AccountId\", \"TranDate\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c88e7090-179b-41a9-9244-5cf12a09e878",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* Calculating Totals Based Upon a Subset of Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5427492b-9a81-4c82-b41a-86c64e6edc12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+------------------+--------+--------+--------+----------+---+\n|AccountId|  TranDate|TranAmt|          SlideAvg|SlideQty|SlideMin|SlideMax|SlideTotal| RN|\n+---------+----------+-------+------------------+--------+--------+--------+----------+---+\n|        1|2011-01-01|  500.0|             500.0|       1|   500.0|   500.0|     500.0|  1|\n|        1|2011-01-15|   50.0|             275.0|       2|    50.0|   500.0|     550.0|  2|\n|        1|2011-01-22|  250.0| 266.6666666666667|       3|    50.0|   500.0|     800.0|  3|\n|        1|2011-01-24|   75.0|             125.0|       3|    50.0|   250.0|     375.0|  4|\n|        1|2011-01-26|  125.0|             150.0|       3|    75.0|   250.0|     450.0|  5|\n|        1|2011-01-28|  175.0|             125.0|       3|    75.0|   175.0|     375.0|  6|\n|        2|2011-01-01|  500.0|             500.0|       1|   500.0|   500.0|     500.0|  1|\n|        2|2011-01-15|   50.0|             275.0|       2|    50.0|   500.0|     550.0|  2|\n|        2|2011-01-22|   25.0|191.66666666666666|       3|    25.0|   500.0|     575.0|  3|\n|        2|2011-01-23|  125.0| 66.66666666666667|       3|    25.0|   125.0|     200.0|  4|\n|        2|2011-01-26|  200.0|116.66666666666667|       3|    25.0|   200.0|     350.0|  5|\n|        2|2011-01-29|  250.0|191.66666666666666|       3|   125.0|   250.0|     575.0|  6|\n|        3|2011-01-01|  500.0|             500.0|       1|   500.0|   500.0|     500.0|  1|\n|        3|2011-01-15|   50.0|             275.0|       2|    50.0|   500.0|     550.0|  2|\n|        3|2011-01-22| 5000.0|            1850.0|       3|    50.0|  5000.0|    5550.0|  3|\n|        3|2011-01-25|  550.0|1866.6666666666667|       3|    50.0|  5000.0|    5600.0|  4|\n|        3|2011-01-27|   95.0|1881.6666666666667|       3|    95.0|  5000.0|    5645.0|  5|\n|        3|2011-01-30| 2500.0|1048.3333333333333|       3|    95.0|  2500.0|    3145.0|  6|\n+---------+----------+-------+------------------+--------+--------+--------+----------+---+\n\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.partitionBy(\"AccountId\").orderBy(\"TranDate\").rowsBetween(-2, 0)\n",
    "windowSpecRowNumber = Window.partitionBy(\"AccountId\").orderBy(\"TranDate\")\n",
    "\n",
    "transactions_df = transactions_df.withColumn(\"SlideAvg\", avg(\"TranAmt\").over(windowSpec)) \\\n",
    "                                 .withColumn(\"SlideQty\", count(\"TranAmt\").over(windowSpec)) \\\n",
    "                                 .withColumn(\"SlideMin\", min(\"TranAmt\").over(windowSpec)) \\\n",
    "                                 .withColumn(\"SlideMax\", max(\"TranAmt\").over(windowSpec)) \\\n",
    "                                 .withColumn(\"SlideTotal\", sum(\"TranAmt\").over(windowSpec)) \\\n",
    "                                 .withColumn(\"RN\", row_number().over(windowSpecRowNumber))\n",
    "\n",
    "transactions_df.select(\"AccountId\", \"TranDate\", \"TranAmt\", \"SlideAvg\", \"SlideQty\", \"SlideMin\", \"SlideMax\", \"SlideTotal\", \"RN\") \\\n",
    "               .orderBy(\"AccountId\", \"TranDate\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33851186-8015-4294-9dbe-95d37dc1fc75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "* Logical Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "052ab43f-5f77-45c9-bc7f-924ae0cb2004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+---------+----------+\n|RowID|      FName|Salary|SumByRows|SumByRange|\n+-----+-----------+------+---------+----------+\n|    1|     George|   800|      800|       800|\n|    2|        Sam|   950|     1750|      1750|\n|    3|      Diane|  1100|     2850|      2850|\n|    4|   Nicholas|  1250|     4100|      5350|\n|    5|     Samuel|  1250|     5350|      5350|\n|    6|   Patricia|  1300|     6650|      6650|\n|    7|      Brian|  1500|     8150|      8150|\n|    8|     Thomas|  1600|     9750|      9750|\n|    9|       Fran|  2450|    12200|     12200|\n|   10|     Debbie|  2850|    15050|     15050|\n|   11|       Mark|  2975|    18025|     18025|\n|   12|      James|  3000|    21025|     24025|\n|   13|    Cynthia|  3000|    24025|     24025|\n|   14|Christopher|  5000|    29025|     29025|\n+-----+-----------+------+---------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "windowSpecRows = Window.orderBy(\"Salary\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "windowSpecRange = Window.orderBy(\"Salary\").rangeBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "logical_df = logical_df.withColumn(\"SumByRows\", sum(\"Salary\").over(windowSpecRows)) \\\n",
    "                       .withColumn(\"SumByRange\", sum(\"Salary\").over(windowSpecRange))\n",
    "\n",
    "logical_df.select(\"RowID\", \"FName\", \"Salary\", \"SumByRows\", \"SumByRange\").orderBy(\"RowID\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36c1770e-de51-4718-8d2c-bd436032f433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Zadanie 4\n",
    "Do tego notatnika dopisz użycie funkcji okienkowych LEAD, LAG, FIRST_VALUE, LAST_VALUE, ROW_NUMBER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1850578b-b12b-4dc7-aa1f-80ddadd1e560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------+----------+--------------+-----------+----------+---------+\n|RowID|      FName|Salary|NextSalary|PreviousSalary|FirstSalary|LastSalary|RowNumber|\n+-----+-----------+------+----------+--------------+-----------+----------+---------+\n|    1|     George|   800|       950|          null|        800|       800|        1|\n|    2|        Sam|   950|      1100|           800|        800|       950|        2|\n|    3|      Diane|  1100|      1250|           950|        800|      1100|        3|\n|    4|   Nicholas|  1250|      1250|          1100|        800|      1250|        4|\n|    5|     Samuel|  1250|      1300|          1250|        800|      1250|        5|\n|    6|   Patricia|  1300|      1500|          1250|        800|      1300|        6|\n|    7|      Brian|  1500|      1600|          1300|        800|      1500|        7|\n|    8|     Thomas|  1600|      2450|          1500|        800|      1600|        8|\n|    9|       Fran|  2450|      2850|          1600|        800|      2450|        9|\n|   10|     Debbie|  2850|      2975|          2450|        800|      2850|       10|\n|   11|       Mark|  2975|      3000|          2850|        800|      2975|       11|\n|   12|      James|  3000|      3000|          2975|        800|      3000|       12|\n|   13|    Cynthia|  3000|      5000|          3000|        800|      3000|       13|\n|   14|Christopher|  5000|      null|          3000|        800|      5000|       14|\n+-----+-----------+------+----------+--------------+-----------+----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.orderBy(\"Salary\")\n",
    "\n",
    "logical_df = logical_df.withColumn(\"NextSalary\", lead(\"Salary\").over(windowSpec)) \\\n",
    "                       .withColumn(\"PreviousSalary\", lag(\"Salary\").over(windowSpec)) \\\n",
    "                       .withColumn(\"FirstSalary\", first(\"Salary\").over(windowSpec)) \\\n",
    "                       .withColumn(\"LastSalary\", last(\"Salary\").over(windowSpec)) \\\n",
    "                       .withColumn(\"RowNumber\", row_number().over(windowSpec))\n",
    "\n",
    "logical_df.select(\"RowID\", \"FName\", \"Salary\", \"NextSalary\", \"PreviousSalary\", \n",
    "                  \"FirstSalary\", \"LastSalary\", \"RowNumber\").orderBy(\"RowID\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Cwiczenia_4_notatnik_2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}